# -*- coding: utf-8 -*-
"""MS1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qyZTCumRi7HFRpEWNbg6sCjVJE77SlQ2

**imports**
"""

# Commented out IPython magic to ensure Python compatibility.
import os
from pathlib import Path
from tqdm import tqdm
import json
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

print("Packages imported.")

"""**Mount Google Drive & set paths**"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

DRIVE_ROOT = Path('/content/drive/MyDrive')  # <- change if your Drive root differs
DATASET_ROOT = DRIVE_ROOT / 'imgdataset'  # put your dataset folder here
OUTPUT_ROOT  = DRIVE_ROOT / 'imgsProcessed'  # outputs will be saved here

print("DATASET_ROOT:", DATASET_ROOT)
print("OUTPUT_ROOT :", OUTPUT_ROOT)

"""**Quick dataset verification & samples**"""

expected = ['correct','puzzle_2x2','puzzle_4x4','puzzle_8x8']

for name in expected:
    p = DATASET_ROOT / name
    print(name.ljust(12), "-> exists:", p.exists(), " | files:", len(list(p.glob('*'))) if p.exists() else 0)

# helper to display small gallery
def show_paths(paths, cols=4, figsize=(14,6)):
    if not paths:
        print("No images to show.")
        return
    rows = (len(paths)+cols-1)//cols
    plt.figure(figsize=(figsize[0], rows*figsize[1]))
    for i,p in enumerate(paths):
        try:
            img = cv2.imread(str(p))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            plt.subplot(rows, cols, i+1); plt.imshow(img); plt.title(p.name); plt.axis('off')
        except Exception as e:
            print("Error showing", p, e)
    plt.show()

samples = []
for name in expected:
    p = DATASET_ROOT / name
    if p.exists():
        samples += list(p.glob('*'))[:4]
show_paths(samples)

"""**Helpers and config**

1. ensure(path) – Folder Creation Helper

This function guarantees that a given directory exists before saving any output files.
If the directory does not exist, it is created automatically (including any missing parent folders).
This prevents runtime errors such as “Folder not found” when writing processed images or tiles.

2. list_images(folder) – Safe Image Loader

This function scans a dataset folder and returns only valid image files based on their extensions
(e.g., .png, .jpg, .jpeg, .bmp, .tif, .tiff).
It filters out any non-image files (such as metadata, temporary files, or hidden system files),
ensuring that the processing pipeline operates only on real images.
This protects the pipeline from unexpected input errors and keeps the workflow consistent.

3. CFG – Centralized Configuration Dictionary

All image-processing parameters used throughout the pipeline are stored in a single configuration dictionary named CFG.
This makes the pipeline easy to tune, maintain, and reproduce.
Instead of scattering “magic numbers” across the code, every parameter is clearly defined and can be updated in one place.

Below is a summary of the purpose of each parameter group:

• CLAHE Parameters

clahe_clip: Controls the strength of contrast enhancement.

clahe_tile: Defines the tile size used by the CLAHE algorithm.
These parameters help normalize lighting and improve local contrast.

• Bilateral Filter Parameters

bilateral_d

bilateral_sigma_color

bilateral_sigma_space
These settings control noise reduction while preserving important edges — essential for later feature extraction.

• Unsharp Mask Parameter

unsharp_amount
Controls the sharpening intensity to enhance fine details and edge structures.

• Adaptive Threshold Parameters

th_block: The size of the local window used for thresholding (must be odd).

th_C: A small adjustment constant to fine-tune the threshold.
These help generate clean binary masks useful for visualizing edges and textures.

• Morphological Cleanup Parameters

morph_kernel: Size of the structuring element.

morph_open_it: Number of opening iterations (removes small noise).

morph_close_it: Number of closing iterations (fills small holes).
These operations help refine thresholded images when necessary.

• Canny Edge Detection Parameters

canny_low

canny_high
These thresholds control the sensitivity of the Canny detector used to extract edges after enhancement.

• Additional Parameters

min_area_ratio: A leftover parameter for contour filtering.
Although not required in the grid-based segmentation workflow, it is kept for flexibility if contour-based methods are explored later.
"""

def ensure(p: Path):
    p.mkdir(parents=True, exist_ok=True)

def list_images(folder: Path):
    return sorted([p for p in folder.glob('*') if p.suffix.lower() in ['.png','.jpg','.jpeg','.bmp','.tif','.tiff']])

# Config (tweak if needed)
CFG = {
    "clahe_clip": 2.0,
    "clahe_tile": (8,8),
    "bilateral_d": 9,
    "bilateral_sigma_color": 75,
    "bilateral_sigma_space": 75,
    "unsharp_amount": 0.9,
    "th_block": 51,
    "th_C": 5,
    "morph_kernel": 5,
    "morph_open_it": 1,
    "morph_close_it": 2,
    "canny_low": 50,
    "canny_high": 150,
    "min_area_ratio": 0.0003,   # not used for grid-splitting but useful ifwe need it
}

"""**Core image processing functions**"""

def to_rgb(img_bgr):
    return cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)

def clahe_grayscale(img_bgr, clipLimit=2.0, tileGridSize=(8,8)):
    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize)
    return clahe.apply(gray)

def bilateral_and_unsharp(gray, bilateral_d=9, bilateral_sigma_color=75, bilateral_sigma_space=75, unsharp_amount=0.9):
    b = cv2.bilateralFilter(gray, bilateral_d, bilateral_sigma_color, bilateral_sigma_space)
    gaussian = cv2.GaussianBlur(b, (0,0), sigmaX=3)
    unsharp = cv2.addWeighted(b, 1.0 + unsharp_amount, gaussian, -unsharp_amount, 0)
    return unsharp

def adaptive_thresh(img_gray, blockSize=51, C=5):
    if blockSize % 2 == 0: blockSize += 1
    return cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                 cv2.THRESH_BINARY_INV, blockSize, C)

def morphological_cleanup(bin_img, kernel_size=5, open_iterations=1, close_iterations=2):
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size,kernel_size))
    opened = cv2.morphologyEx(bin_img, cv2.MORPH_OPEN, k, iterations=open_iterations)
    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, k, iterations=close_iterations)
    return closed

def compute_canny(img_gray, low=50, high=150):
    return cv2.Canny(img_gray, low, high)

def split_into_grid(img, rows, cols):
    H, W = img.shape[:2]
    h_step = H // rows
    w_step = W // cols
    blocks = []
    for r in range(rows):
        for c in range(cols):
            y1, y2 = r*h_step, (r+1)*h_step if r<rows-1 else H
            x1, x2 = c*w_step, (c+1)*w_step if c<cols-1 else W
            block = img[y1:y2, x1:x2]
            blocks.append(((r,c),(x1,y1,x2,y2), block))
    return blocks

"""**Single-image dry run (test and inspect)**"""

# 6 - Single image dry-run: choose a small puzzle image to verify pipeline
# Edit this if you want to test a specific image path
test_folder = DATASET_ROOT / 'puzzle_2x2'
img_list = list_images(test_folder)
if not img_list:
    raise RuntimeError(f"No images found in {test_folder}. Check dataset location.")
test_img_path = img_list[0]
print("Testing image:", test_img_path)

img_bgr = cv2.imread(str(test_img_path))
H,W = img_bgr.shape[:2]

# Step A: Enhancement on full image
clahe = clahe_grayscale(img_bgr, clipLimit=CFG['clahe_clip'], tileGridSize=CFG['clahe_tile'])
unsharp = bilateral_and_unsharp(clahe,
                                bilateral_d=CFG['bilateral_d'],
                                bilateral_sigma_color=CFG['bilateral_sigma_color'],
                                bilateral_sigma_space=CFG['bilateral_sigma_space'],
                                unsharp_amount=CFG['unsharp_amount'])

# Step B: Optional threshold & morph (we'll keep for visualization)
th = adaptive_thresh(unsharp, blockSize=CFG['th_block'], C=CFG['th_C'])
clean_mask = morphological_cleanup(th, kernel_size=CFG['morph_kernel'],
                                   open_iterations=CFG['morph_open_it'],
                                   close_iterations=CFG['morph_close_it'])

# Step C: Edge detection
edges = compute_canny(unsharp, low=CFG['canny_low'], high=CFG['canny_high'])

# Step D: Grid-split into tiles (based on folder name)
rows = 2; cols = 2   # puzzle_2x2
tiles_rgb = split_into_grid(to_rgb(img_bgr), rows, cols)
tiles_enh = split_into_grid(unsharp, rows, cols)   # unsharp is grayscale
tiles_edges = split_into_grid(edges, rows, cols)

# Visualization
plt.figure(figsize=(16,10))
plt.subplot(2,3,1); plt.imshow(to_rgb(img_bgr)); plt.title('Original'); plt.axis('off')
plt.subplot(2,3,2); plt.imshow(clahe, cmap='gray'); plt.title('CLAHE gray'); plt.axis('off')
plt.subplot(2,3,3); plt.imshow(unsharp, cmap='gray'); plt.title('Bilateral + Unsharp'); plt.axis('off')
plt.subplot(2,3,4); plt.imshow(th, cmap='gray'); plt.title('Adaptive Thresh'); plt.axis('off')
plt.subplot(2,3,5); plt.imshow(clean_mask, cmap='gray'); plt.title('Morph Clean'); plt.axis('off')
plt.subplot(2,3,6); plt.imshow(edges, cmap='gray'); plt.title('Canny edges'); plt.axis('off')
plt.show()

# Show tiles (RGB and edges)
for view_name, tiles in [('rgb', tiles_rgb), ('enh', tiles_enh), ('edges', tiles_edges)]:
    print("Tiles view:", view_name)
    imgs = [t[2] for t in tiles]
    show_paths([])  # print separator
    if view_name=='rgb':
        show_paths([Path(test_img_path.parent) / "dummy.png"]*0)  # no-op
    cols = cols
    rows = (len(imgs)+cols-1)//cols
    plt.figure(figsize=(12, 3*rows))
    for i,im in enumerate(imgs):
        plt.subplot(rows, cols, i+1)
        if view_name=='enh' or view_name=='edges':
            plt.imshow(im, cmap='gray'); plt.axis('off')
        else:
            plt.imshow(im); plt.axis('off')
    plt.suptitle(f"{test_img_path.name} - {view_name} tiles")
    plt.show()

"""**Save artifacts for test image**"""

out_test_dir = OUTPUT_ROOT / 'test_run' / test_img_path.stem
ensure(out_test_dir)

cv2.imwrite(str(out_test_dir / f'{test_img_path.stem}_orig.png'), img_bgr)
cv2.imwrite(str(out_test_dir / f'{test_img_path.stem}_enhanced.png'), unsharp)
cv2.imwrite(str(out_test_dir / f'{test_img_path.stem}_mask.png'), clean_mask)
cv2.imwrite(str(out_test_dir / f'{test_img_path.stem}_edges.png'), edges)

# Save tiles and tile metadata
tiles_dir = out_test_dir / 'tiles'; ensure(tiles_dir)
tile_meta = []
for (r,c),(x1,y1,x2,y2),tile in tiles_rgb:
    tile_name = f"tile_r{r}_c{c}.png"
    tile_path = tiles_dir / tile_name
    plt_tile = tile.copy()
    # convert RGB image to BGR for cv2.imwrite
    cv2.imwrite(str(tile_path), cv2.cvtColor(plt_tile, cv2.COLOR_RGB2BGR))
    tile_meta.append({"tile": tile_name, "row": int(r), "col": int(c), "bbox":[int(x1),int(y1),int(x2),int(y2)]})

with open(out_test_dir / 'tiles_metadata.json','w') as f:
    json.dump(tile_meta, f, indent=2)

print("Test artifacts saved to", out_test_dir)

"""**Batch processing (process all puzzle folders)**"""

ensure(OUTPUT_ROOT)
folders = {
    'puzzle_2x2': (2,2),
    'puzzle_4x4': (4,4),
    'puzzle_8x8': (8,8),
}

for folder_name, (rows, cols) in folders.items():
    in_folder = DATASET_ROOT / folder_name
    out_folder = OUTPUT_ROOT / folder_name
    if not in_folder.exists():
        print("Skipping (not found):", in_folder)
        continue
    img_list = list_images(in_folder)
    print(f"Processing {folder_name}: {len(img_list)} images  -> grid {rows}x{cols}")
    for p in tqdm(img_list):
        try:
            img_bgr = cv2.imread(str(p))
            if img_bgr is None:
                print("Read error:", p); continue
            # preprocess full image
            clahe = clahe_grayscale(img_bgr, clipLimit=CFG['clahe_clip'], tileGridSize=CFG['clahe_tile'])
            unsharp = bilateral_and_unsharp(clahe,
                                            bilateral_d=CFG['bilateral_d'],
                                            bilateral_sigma_color=CFG['bilateral_sigma_color'],
                                            bilateral_sigma_space=CFG['bilateral_sigma_space'],
                                            unsharp_amount=CFG['unsharp_amount'])
            th = adaptive_thresh(unsharp, blockSize=CFG['th_block'], C=CFG['th_C'])
            clean_mask = morphological_cleanup(th, kernel_size=CFG['morph_kernel'],
                                               open_iterations=CFG['morph_open_it'],
                                               close_iterations=CFG['morph_close_it'])
            edges = compute_canny(unsharp, low=CFG['canny_low'], high=CFG['canny_high'])

            # prepare outputs
            out_img_dir = out_folder / p.stem
            ensure(out_img_dir)
            cv2.imwrite(str(out_img_dir / f"{p.stem}_orig.png"), img_bgr)
            cv2.imwrite(str(out_img_dir / f"{p.stem}_enhanced.png"), unsharp)
            cv2.imwrite(str(out_img_dir / f"{p.stem}_mask.png"), clean_mask)
            cv2.imwrite(str(out_img_dir / f"{p.stem}_edges.png"), edges)

            # split into tiles and save tiles + metadata
            tiles_rgb = split_into_grid(to_rgb(img_bgr), rows, cols)
            tiles_enh = split_into_grid(unsharp, rows, cols)
            tiles_edges = split_into_grid(edges, rows, cols)

            tiles_dir = out_img_dir / 'tiles'; ensure(tiles_dir)
            metadata = []
            for (r,c),(x1,y1,x2,y2),tile_rgb in tiles_rgb:
                tile_name = f"{p.stem}_r{r}_c{c}.png"
                tile_path = tiles_dir / tile_name
                cv2.imwrite(str(tile_path), cv2.cvtColor(tile_rgb, cv2.COLOR_RGB2BGR))

                # also save enhanced and edge versions for the tile
                # find corresponding enhanced/edge tile by index
                idx = r*cols + c
                tile_enh = tiles_enh[idx][2]
                tile_edge = tiles_edges[idx][2]
                cv2.imwrite(str(tiles_dir / f"{p.stem}_r{r}_c{c}_enh.png"), tile_enh)
                cv2.imwrite(str(tiles_dir / f"{p.stem}_r{r}_c{c}_edge.png"), tile_edge)

                metadata.append({
                    "tile_name": tile_name,
                    "row": int(r), "col": int(c),
                    "bbox": [int(x1), int(y1), int(x2), int(y2)]
                })

            with open(out_img_dir / 'tiles_metadata.json','w') as f:
                json.dump(metadata, f, indent=2)

        except Exception as e:
            print("Error processing", p, e)

print("Batch processing complete. Outputs saved under:", OUTPUT_ROOT)
